---
title: "Lab 3: Continuous Probability"
date: February 4, 2026
---


```{r echo=F}
library(ggplot2)
theme_set(theme_classic())
```

## Review

-   Last week we learned how to simulate data from discrete distributions and create visualizations.

-   If variable $X$ follows a discrete distribution, it means the outcome of the variable $X$ is categorical:

$$X \sim binom(n, p)$$
```{r}
dbinom(x = c(0:3), size = 3, prob=0.5)
```

-   Today, we will learn about continuous distributions, for which probabilities are found for an interval of $X$ instead of at specific values.

## Overview

Major differences between continuous distributions and discrete distributions:

  -   Probability vs. density
    
Summarizing continuous distributions

  -   Mean, Median, Mode
  -   Quantiles 
  -   Cumulative distribution
  -   Intervals

## Features of Continuous Variables

In discrete distributions, we read probabilities directly from `d` functions:

```{r}
dbinom(x = 0:3, size = 3, prob=0.5)
```

However, continuous distributions give **densities** instead of **probabilities**:

```{r}
dexp(x = 0:3, rate = 2)
```

Note: densities can be >1


## Features of Continuous Distributions

Probabilities for continuous distributions are calculated as **areas under the curve** corresponding to **intervals** of the variable

-   For example, 68% of the standard normal distribution is between -1 and 1.

```{r echo = F}
ggplot(data = data.frame(x = c(-3:3)), aes(x))+
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1))+
  geom_area(stat = "function", fun = dnorm, 
            xlim = c(-1,1), fill = "grey", alpha = 0.6)
```

## Calculate Probability

- `p` functions give **cumulative probabilities**, the proportion of the distribution that is below a certain point `q`:

```{r}
pnorm(q = 1, mean = 0, sd = 1)
```

```{r}
ggplot(data = data.frame(x = c(-3:3)), aes(x))+
  stat_function(fun = dnorm, args = list(mean = 0, sd = 1))+
  geom_area(stat = "function", fun = dnorm, 
            xlim = c(-3,1), fill = "grey")
```


## Calculate Probability

We can arrive at the same result by integrating over the `dnorm` function:

```{r}
integrate(dnorm, lower = -Inf, upper = 1, mean = 0, sd = 1)
```


Integration can be helpful over a specific range of values:
    
```{r}
integrate(dnorm, lower = -1, upper = 1, mean = 0, sd = 1)
```

How to get the same result with `pnorm`:

```{r}
pnorm(1, mean = 0, sd = 1) - pnorm(-1, mean = 0, sd = 1)
```

## Calculate Probability

Quantiles and cumulative distribution

  -   `q` represents the quantile of a function
  -   `p` represents the cumulative distribution
    
For example, if we want to investigate the probability **below** 1 of the standard normal distribution:

```{r}
pnorm(1, mean=0, sd=1) #lower.tail = TRUE
```


If we want to investigate the probability **above** 1 of the standard normal distribution:

```{r}
pnorm(1, mean=0, sd=1, lower.tail = FALSE)
```

## Calculate Probability

Quantiles and cumulative distribution

- The quantile function is the inverse function of the cumulative distribution function. 

- The quantile is the point of the distribution below which lies  a certain % of the data:

```{r}
qnorm(p = 0.8, mean = 0, sd = 1)
```

`qnorm` is the inverse of `pnorm`:

```{r}
pnorm(q = 0.8416212, mean = 0, sd = 1)
```

## Probability through Simulation

-   Simulate many observations from the distribution.
-   Find the proportion of data in a certain interval.
-   Below, we take 10,000 samples. The more data we simulate, the more accurate the result.

```{r}
set.seed(8949)
sample_10000 <- rnorm(10000, mean = 0, sd = 1)
mean(sample_10000<1 & sample_10000>-1)
```

The simulated answer is close to the exact answer:

```{r}
pnorm(q = 1, mean = 0, sd = 1) - pnorm(q = -1, mean = 0, sd = 1)
```

Although it may seem silly to simulate data when an exact answer is available, simulation is useful when the exact probability function is not available.


## Summarizing Empirical Distributions

Central tendency

- Mean, median, mode

- Many distributions have known expressions for these quantities

- See <https://leahmf.com/distributions> or search online


**How to summarize central tendency for samples of data, such as simulated data?**
    
## Summarizing Empirical Distributions

We can use simulation to help understand the distribution of empirical samples.

- Mean:
```{r}
mean(sample_10000)
```

- Median:

```{r}
median(sample_10000)
```

## Summarizing Empirical Distributions

How to find the **mode** from a sample of continuous values?

- For categorical outcomes, the mode is the highest frequency value

- For continuous outcomes, it is very rare to observe the exact same value twice, for example:

```{r}
length(unique(sample_10000))
```

-   We have 10000 different values, which means that every point is the mode (most frequently occurring point).

-   We can instead find a **highest density interval** to find the most likely **region** of continuous values.

## Summarizing Empirical Distributions

Visualizing the density plot is also a useful method to understand the distribution.

```{r}
sample_10000_plot<-data.frame(sample_10000)
ggplot(sample_10000_plot, aes(x = sample_10000))+
  geom_density()
```

## Summarizing Empirical Distributions

Additionally, **intervals** are helpful to summarize simulated data.

-   Percentile Intervals
    - Represents the bounds of the center ___% of values
    - A 90% percentile interval is bounded by the .05 and .95 quantiles

```{r}
quantile(sample_10000, probs = c(0.05, 0.95))
```

## Summarizing Empirical Distributions

Highest posterior density (HPD) intervals

-  HPD intervals give the narrowest interval including certain percent of samples.
```{r}
library(coda)
HPDinterval(as.mcmc(sample_10000), prob=0.95)
```

-   `as.mcmc` can change the dataset to the type of "Markov Chain Monte Carlo" object used the `coda` package. We will talk more about it later in this semester.

## Other Distributions in R

-   In lecture, you learned about many continuous distributions. It is easy to simulate data from them in R:

-   `rexp`: exponential

-   `rnorm`: normal

-   `rlnorm`: log-normal

-   `rgamma`: gamma

-   `rbeta`: beta

-   Before using any of them, it is a good habit to visualize each distribution.

## Some Useful Functions in R

- For example the exponential distribution with $\lambda = 1$:

```{r}
ggplot(data.frame(x = c(0, 3), y = c(0, 1)),
       aes(x = x, y = y))+
  stat_function(fun = dexp, args = c(rate = 1))
```


## Activity

1. First, you will work with the gamma distribution.

  - Identify the parameters and allowed parameter ranges of the gamma distribution. Choose specific values to work with.
  
  - Use `ggplot` and `stat_function` to draw a gamma distribution curve with your chosen parameters.

  -   Simulate 10,000 samples from the gamma distribution with your chosen parameters. 
  
  -   Visualize the distribution of your simulated data. 
  
  -   Calculate the 95% equal-tail interval and HDPI from your simulated data.

  -   Compare your results with a classmate's. If you chose different parameter values, how do the parameters affect your results?

2. Repeat the activity for the beta distribution with parameters of your choice.

