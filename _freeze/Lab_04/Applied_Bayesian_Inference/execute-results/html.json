{
  "hash": "1ed4e3902026e0d40c613096b20636e3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 4: Applied Bayesian Inference\"\ndate: February 11, 2026\neditor_options: \n  chunk_output_type: console\n---\n\n## Goals\n\n\n::: {.cell}\n\n:::\n\n\n* Fit and evaluate simple linear regression models with `brms`\n\n* Prior predictive simulation\n\nR packages for today (install if needed):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(bayesplot)\nlibrary(tidybayes)\n```\n:::\n\n\n## Model Setup\n\nIn the Tour-de-France example from lecture, we predicted rider weight in kilograms $w_i$ from height $h_i$ in centimeters\n\n\n$$\\omega_i \\sim Normal (\\mu_i, \\sigma)$$\n\n$$\\mu_i = a + b (h_i - \\bar{h})$$\nThe priors we chose in lecture are:\n\n* Intercept $a \\sim N(66.5, 2)$\n\n* Slope $b \\sim N(1, .5)$\n\n* Standard error $\\sigma \\sim Exp(.25)$\n\n\n## Model Setup\n\nIf you want to follow along, you can download the `TDF.csv` data from Blackboard.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nTDF <- read_csv(\"TDF.csv\") # Read in the data\nTDF<-TDF %>% \n  # mean-center height and convert to cm\n  mutate (HeightC = (Height - mean(Height))*100)\n```\n:::\n\n\nThe formula in `brms` is:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(brms)\nbrms_form <- Weight ~ HeightC\n```\n:::\n\n\n## Model Setup\n\nUse `get_prior` to see which `class` to set when specifying priors.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_prior(brms_form, data = TDF, \n          family = gaussian(link = \"identity\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n``` nowrap-code\n                 prior     class    coef group resp dpar nlpar lb ub\n                (flat)         b                                    \n                (flat)         b HeightC                            \n student_t(3, 70, 7.4) Intercept                                    \n  student_t(3, 0, 7.4)     sigma                                0   \n       source\n      default\n (vectorized)\n      default\n      default\n```\n\n\n:::\n:::\n\n\nIn `brms`, the `prior()` function with the `class` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrms_prior<-prior(normal(66.5, 2), class = \"Intercept\")+\n            prior(normal(1, .5), class = \"b\")+\n            prior(exponential(.25), class = \"sigma\")\n```\n:::\n\n\n## Model Fitting\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod <- brm(brms_form, data = TDF, \n           family = gaussian(link = \"identity\"),\n           prior = brms_prior)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nusing C compiler: ‘Apple clang version 17.0.0 (clang-1700.6.3.2)’\nusing SDK: ‘MacOSX26.2.sdk’\nclang -arch arm64 -std=gnu2x -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/Core:19:\n/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: 'cmath' file not found\n  679 | #include <cmath>\n      |          ^~~~~~~\n1 error generated.\nmake: *** [foo.o] Error 1\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 2.9e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.29 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 1:                0.008 seconds (Sampling)\nChain 1:                0.018 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.01 seconds (Warm-up)\nChain 2:                0.008 seconds (Sampling)\nChain 2:                0.018 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.011 seconds (Warm-up)\nChain 3:                0.008 seconds (Sampling)\nChain 3:                0.019 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.011 seconds (Warm-up)\nChain 4:                0.007 seconds (Sampling)\nChain 4:                0.018 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n\n## Model Evaluation\n\nTo view a summary of the posterior distribution for each parameter, we can use `print()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Weight ~ HeightC \n   Data: TDF (Number of observations: 179) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept    69.31      0.36    68.62    70.01 1.00     4043     2564\nHeightC       0.78      0.06     0.68     0.89 1.00     3199     2663\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     4.86      0.26     4.37     5.41 1.00     4357     2871\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n## Model Evaluation\n\nThe results shown by `print()` are summaries of a **Monte Carlo sample** from the posterior of each parameters' distribution. \n\nTo see the draws themselves:\n\n::: panel-tabset\n\n## Way 1\n\nFrom the `brms` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nas_draws_df(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A draws_df: 1000 iterations, 4 chains, and 6 variables\n   b_Intercept b_HeightC sigma Intercept lprior lp__\n1           69      0.68   5.1        69   -5.5 -542\n2           69      0.72   4.8        69   -5.3 -540\n3           70      0.82   4.9        70   -5.8 -540\n4           70      0.81   5.0        70   -5.7 -540\n5           69      0.86   4.8        69   -5.4 -540\n6           69      0.74   4.6        69   -5.3 -540\n7           70      0.72   5.1        70   -6.0 -541\n8           69      0.70   5.0        69   -5.7 -540\n9           69      0.85   4.7        69   -5.2 -540\n10          69      0.73   5.1        69   -5.7 -540\n# ... with 3990 more draws\n# ... hidden reserved variables {'.chain', '.iteration', '.draw'}\n```\n\n\n:::\n:::\n\n\n## Way 2\n\nFrom the `tidybayes` package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod %>% gather_draws(b_Intercept, b_HeightC, sigma)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12,000 × 5\n# Groups:   .variable [3]\n   .chain .iteration .draw .variable   .value\n    <int>      <int> <int> <chr>        <dbl>\n 1      1          1     1 b_Intercept   69.0\n 2      1          2     2 b_Intercept   69.0\n 3      1          3     3 b_Intercept   69.7\n 4      1          4     4 b_Intercept   69.6\n 5      1          5     5 b_Intercept   69.2\n 6      1          6     6 b_Intercept   69.0\n 7      1          7     7 b_Intercept   69.8\n 8      1          8     8 b_Intercept   69.4\n 9      1          9     9 b_Intercept   69.0\n10      1         10    10 b_Intercept   69.5\n# ℹ 11,990 more rows\n```\n\n\n:::\n:::\n\n\n:::\n\n\n## Model Evaluation\n\nCompare the means and standard deviations to the results of `print(mod)`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod %>% \n  gather_draws(b_Intercept, b_HeightC, sigma) %>% \n  mean_qi()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 7\n  .variable   .value .lower .upper .width .point .interval\n  <chr>        <dbl>  <dbl>  <dbl>  <dbl> <chr>  <chr>    \n1 b_HeightC    0.784  0.680  0.893   0.95 mean   qi       \n2 b_Intercept 69.3   68.6   70.0     0.95 mean   qi       \n3 sigma        4.86   4.37   5.41    0.95 mean   qi       \n```\n\n\n:::\n:::\n\n\n\n## Model Evaluation\n\nTo plot the posterior mean for $\\mu$ (best-fit line) with a 95% interval, we can use the `conditional_effects` function in `brms`.\n\n* Use the argument `method = \"posterior_linpred\"` to plot the best-fit line.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(mod, method = \"posterior_linpred\"))\n```\n\n::: {.cell-output-display}\n![](Applied_Bayesian_Inference_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n## Model Evaluation\n\nWe may also wish to reference the raw data by adding `points = TRUE`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(mod, method = \"posterior_linpred\"),\n     points = TRUE)\n```\n\n::: {.cell-output-display}\n![](Applied_Bayesian_Inference_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\nNote: the best-fit line seems to do a good job of describing the average predictions. The 95% error band is close to the line, indicating high certainty.\n\n## Model Evaluation\n\nWe can use a similar plot to see the model-predicted range of observations.\n\n* Use `method = \"posterior_predict\"` for the 95% predicted range of observations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(mod, method = \"posterior_predict\"),\n     points = TRUE)\n```\n\n::: {.cell-output-display}\n![](Applied_Bayesian_Inference_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\nWe want approximately `95% of observations to be in the error band. Not bad!\n\n## Prior Predictive Simulation\n\nHow to choose priors?!?\n\nAlthough commonly used, flat or noninformative priors are not usually the best choice. We often know *something* about what our results should look like.\n\n* What are the ranges of the predictor and criterion variables?\n\n* Do you expect the relationship to be positive or negative? Strong or weak?\n\n* What are the allowable ranges of the parameters?\n\n  - e.g., the standard error $\\sigma$ must be positive \n\n## Prior Predictive Simulation\n\nDon't worry too much about being \"correct\". Worry instead about encoding your level of preknowledge/uncertainty into your priors. If your guesses are far away from truth, the data will suggest something different than your priors. Ultimately, your results may be a little less certain (have higher credible intervals), but appropriately so!\n\nVisualization is very useful for prior predictive simulation.\n\n## Prior Predictive Simulation\n\nNew Example: How has the weather in NYC changed over time?\n\nThe following dataset includes the average January daily high temperature (Fahrenheit) in NYC from 1918 to 2024.\n\n* You just survived January in NYC, so you should have some familiarity with the topic ;)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemps <- read_csv(\"weather.csv\")\ntemps %>% glimpse\n```\n\n::: {.cell-output .cell-output-stdout}\n\n``` nowrap-code\nRows: 107\nColumns: 2\n$ YEAR          <dbl> 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 19…\n$ Avg_High_Temp <dbl> 45.54839, 36.67742, 43.09677, 39.45161, 39.45161, 47.387…\n```\n\n\n:::\n:::\n\n\n## Prior Predictive Simulation\n\nModel setup:\n\n$$t_i \\sim Normal (\\mu_i, \\sigma)$$\n$$\\mu_i = a + b (y_i - \\bar{y})$$\nParameters:\n\n* $a$: average predicted temperature in average year 1971\n* $b$: predicted change in average temperature each year\n* $\\sigma$: standard deviation of how much observed temperatures are expected to change from the prediction\n\n## Prior Predictive Simulation\n\nFrom experience, I may guess (you may guess differently):\n\n* that the average high temperature in 1971 was around 35 degrees\n  \n  - I think that this is within 5 degrees or so of being correct\n  \n  - Translated to a prior: $a \\sim N(35, 5)$\n  \n* that temperatures have increased over time, but not too much\n\n  - Perhaps 1/10 of a degree each year\n  \n  - I am not too certain, maybe this prediction is off by about .5 degrees\n  \n  - Translated to a prior: $b \\sim N(.1, .5)$\n  \n* that there are noticeable year-to-year fluctuations in January temperatures\n  \n  - Perhaps up to 10 degrees\n  \n  - Translated to a prior: $\\sigma \\sim Exp(0.1)$ (such that $E(\\sigma) = 10$)\n\n## Prior Predictive Simulation\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemps_prior <- prior(normal(35, 5), class = \"Intercept\") + \n               prior(normal(.1, .5), class = \"b\") +\n               prior(exponential(.1), class = \"sigma\")\n```\n:::\n\n\nIt is convenient to run the model with these priors but with the argument `sample_prior = \"only\"`. This will give you samples from the **prior distributions** rather than the posterior distributions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_samps <- brm(Avg_High_Temp ~ YEAR, temps, \n                   family = gaussian(link = \"identity\"),\n                   prior = temps_prior,\n                   sample_prior = \"only\")\n```\n:::\n\n\nBecause we use `brms` to generate samples from the prior, we can use similar functions to analyze the prior as we used to analyze the posterior.\n\n## Prior Predictive Simulation\n\nThe argument `spaghetti = TRUE` draws predictions of the best-fit line.\n\n* For spaghetti plots, set `ndraws = #`, otherwise the code may take a long time to run.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(prior_samps, method = \"posterior_linpred\", \n                         spaghetti = TRUE, ndraws = 500))\n```\n\n::: {.cell-output-display}\n![](Applied_Bayesian_Inference_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n## Prior Predictive Simulation\n\nWe might decide that the plot on the last slide allows too many negative slopes. Let's update our prior by reducing the variability of the slopes:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemps_prior2 <- prior(normal(35, 5), class = \"Intercept\") + \n                prior(normal(.1, .1), class = \"b\") +\n                prior(exponential(.1), class = \"sigma\")\n```\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_samps2 <- brm(Avg_High_Temp ~ YEAR, temps, \n                    family = gaussian(link = \"identity\"),\n                    prior = temps_prior2,\n                    sample_prior = \"only\")\n```\n:::\n\n\n## Prior Predictive Simulation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(prior_samps2, method = \"posterior_linpred\", \n                         spaghetti = TRUE, ndraws = 500))\n```\n\n::: {.cell-output-display}\n![](Applied_Bayesian_Inference_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\nRemember that this is the prediction for the mean regression line, not for individual observations. Are you satisfied with this prior? Why or why not?\n\n## Prior Predictive Simulation\n\nWe also need to evaluate our prior on $\\sigma$. This controls where we expect our **actual observations** to be.\n\n* With `conditional_effects` use `method = \"posterior_predict\"` to plot a 95% credible interval band.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(prior_samps2, method = \"posterior_predict\"))\n```\n\n::: {.cell-output-display}\n![](Applied_Bayesian_Inference_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n## Group Activity\n\nAs a class, let's decide whether to make any further adjustments to our priors.\n\nOn your own computer, read in the data (download from Blackboard):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\ntemps <- read_csv(\"weather.csv\")\n```\n:::\n\n\nSet the priors (replace `...` with your priors):\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemps_prior <- prior(..., class = \"Intercept\") + \n               prior(..., class = \"b\") +\n               prior(..., class = \"sigma\")\n```\n:::\n\n\nFit the model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntemps_mod <- brm(Avg_High_Temp ~ YEAR, temps, \n                 family = gaussian(link = \"identity\"),\n                 prior = temps_prior)\n```\n:::\n\n\n## Group Activity\n\nEvaluate the model using the following code. Let's discuss the results as a group.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(temps_mod)\nplot(conditional_effects(temps_mod, method = \"posterior_linpred\", prob = .95),\n     points = TRUE)\nplot(conditional_effects(temps_mod, method = \"posterior_predict\", prob = .95),\n     points = TRUE)\n```\n:::\n\n\n## Independent Activity\n\nSuppose that you wish you predict Life Expectancy (in years) from the Percent (0-100) of a population that has graduated high school in the U.S. in the 1970s using simple linear regression. \n\n1. Write down the model form using $a$, $b$, and $\\sigma$ as the symbols for the intercept, slope, and standard error that you will estimate.\n\n2. Based on the above information and your own knowledge, conduct prior predictive simulation for $a$, $b$, and $\\sigma$.\n\n    - Your knowledge: what is a reasonable range of life expectancies? What type of relationship do you expect between these variables, and how strong do you think that relationship might be?\n  \n\n::: {.cell}\n\n```{.r .cell-code}\ndata(state)\nbrms_form <- `Life Exp` ~ `HS Grad`\ndata <- state.x77\n\npriors <- ## add your chosen priors here!\n\nprior_samps <- brm(formula = brms_form, data = data, \n                   family = gaussian(link = \"identity\"),\n                   prior = priors, sample_prior = \"only\")\n```\n:::\n\n\n## Independent Activity\n\n3. Compare your choices to your classmate's. Remember to **not** peek at the actual data during this step. \n  \n4. If time allows, fit the model using `brms` with your choice of priors and evaluate the output.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}