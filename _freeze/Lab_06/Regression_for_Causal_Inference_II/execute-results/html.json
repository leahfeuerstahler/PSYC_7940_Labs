{
  "hash": "eea6f894b1eca2da862bf99f9d254f0a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 6: Regression for Causal Inference II\"\ndate: February 25, 2026\n---\n\n## Overview\n\n-   Thinking generatively to simulate data\n\n-   Missing data\n\nPackages for today (install if needed):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(mice)\n```\n:::\n\n\n\n## Thinking Generatively\n\nOne benefit of learning about DAGs and causal inference is that it enables us to think **generatively**\n\n- What are the pathways by which data are **generated**?\n\n\nBenefits of thinking generatively:\n\n- Enables us to better understand and interpret output\n\n- Allows us to **test** our models with **simulated data** that meets our expectations\n\n\n## Simulation\n\nThe biggest advantage of using simulated data is that we already know the **truth**. By comparing the estimated model with the **truth**, we have a powerful tool to help us understand anything that may go wrong with our model.\n\nLet us consider the following model:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Regression_for_Causal_Inference_II_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n## Simulation\n\nThis model implies:\n\n* Well-being is directly affected by sex and support\n\n* Support is directly affected by social media use\n\n::: {.callout-note}\n\nYou may hypothesize that there is a more complex relationship between sex and support and/or social media. For instance, if you hypothesize that social support affects well-being differently for different sexes, you may consider moderation/interaction models. Although we don't cover moderation explicitly in this class, you read about it in Ch. 8 of the *Rethinking* textbook.\n\n:::\n\n\n## Simulation\n\nIn our DAG, both `sex` and `soc_med` are unaffected by other variables in our model, so let's start by generating these values.\n\n* Let's generate 100 values\n\n* `sex` has 3 levels: let's assume 45% female, 45% male, and 10% other\n\n* `soc_med` is continuous: let's generate from a standard normal distribution\n\n* Other choices are possible, too!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(235)\n\nN <- 100\n\nsex <- factor(sample(x = c(\"female\", \"male\", \"other\"), size = N,\n                     replace = TRUE, prob = c(.45, .45, .10)))\n\nsoc_med <- rnorm(N)\n```\n:::\n\n\n\n## Simulation\n\nNext, `support` is caused by `soc_med`. Let's assume that this is a positive relationship. One way to generate data based on this causal relationship is to have `soc_med` values determine the mean of the generating normal distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsupport <- rnorm(N, mean = soc_med)\n```\n:::\n\n\n\n## Simulation\n\nFinally, we generate values of `wb` that is affected by *both* `support` and `sex`. The following generates data assuming that well-being for males > females > other\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsexeffect <- case_when(sex == \"male\" ~ 1,\n                       sex == \"female\" ~ 0.5,\n                       sex == \"other\" ~ -0.5)\n\nwb <- rnorm(N, mean = support + sexeffect)\n```\n:::\n\n\n## Simulation\n\nCombine into a dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_data <- tibble(sex, soc_med, support, wb)\n```\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sim_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  sex    soc_med support     wb\n  <fct>    <dbl>   <dbl>  <dbl>\n1 other  -1.37    -1.68  -3.10 \n2 female  0.672   -0.981 -0.261\n3 female  0.0601  -1.11   0.195\n4 male    0.722    1.28   4.44 \n5 male   -0.0172   0.980  2.69 \n6 female  0.332   -1.03   0.103\n```\n\n\n:::\n:::\n\n\n## Simulation\n\nInspect the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nGGally::ggpairs(sim_data)\n```\n\n::: {.cell-output-display}\n![](Regression_for_Causal_Inference_II_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n\n## Simulation\n\nRescale our variables like we did in the previous lab:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_data <- sim_data %>%\n  mutate(soc_med = (soc_med - mean(soc_med)) / sd(soc_med),\n         support = (support - mean(support)) / sd(support),\n         wb = (wb - mean(wb)) / sd(wb))\n```\n:::\n\n\n\nFit the model using priors from last week:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_mod<- bf(wb ~ 0 + sex + support + soc_med) + \n          bf(support ~ 0 + sex + soc_med) + \n          set_rescor(FALSE)\n\nsim_prior <- prior(normal(0, .2), class = \"b\", coef = \"sexfemale\", resp = \"wb\") +\n             prior(normal(0, .2), class = \"b\", coef = \"sexmale\", resp = \"wb\") +\n             prior(normal(0, .2), class = \"b\", coef = \"sexother\", resp = \"wb\") +\n             prior(normal(0, .5), class = \"b\", coef = \"soc_med\", resp = \"wb\") +\n             prior(normal(0, .5), class = \"b\", coef = \"support\", resp = \"wb\") +\n             prior(exponential(1), class = \"sigma\", resp = \"wb\") +\n             prior(normal(0, .2), class = \"b\", coef = \"sexfemale\", resp = \"support\") +\n             prior(normal(0, .2), class = \"b\", coef = \"sexmale\", resp = \"support\") +\n             prior(normal(0, .2), class = \"b\", coef = \"sexother\", resp = \"support\") +\n             prior(normal(0, .5), class = \"b\", coef = \"soc_med\", resp = \"support\") +\n             prior(exponential(1), class = \"sigma\", resp = \"support\")\n\nsim_fit <- brm(formula = sim_mod, data = sim_data, \n               family = gaussian(link = \"identity\"), prior = sim_prior)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nusing C compiler: ‘Apple clang version 17.0.0 (clang-1700.6.3.2)’\nusing SDK: ‘MacOSX26.2.sdk’\nclang -arch arm64 -std=gnu2x -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/Core:19:\n/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: 'cmath' file not found\n  679 | #include <cmath>\n      |          ^~~~~~~\n1 error generated.\nmake: *** [foo.o] Error 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3.7e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.37 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.021 seconds (Warm-up)\nChain 1:                0.018 seconds (Sampling)\nChain 1:                0.039 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.02 seconds (Warm-up)\nChain 2:                0.018 seconds (Sampling)\nChain 2:                0.038 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 2e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.022 seconds (Warm-up)\nChain 3:                0.019 seconds (Sampling)\nChain 3:                0.041 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 2e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.022 seconds (Warm-up)\nChain 4:                0.019 seconds (Sampling)\nChain 4:                0.041 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n\n## Simulation\n\nInspect the fitted model results:\n\n* Note which effects have 0 in their CI. Do these patterns match the data generation?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(sim_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n``` nowrap-code\n Family: MV(gaussian, gaussian) \n  Links: mu = identity\n         mu = identity \nFormula: wb ~ 0 + sex + support + soc_med \n         support ~ 0 + sex + soc_med \n   Data: sim_data (Number of observations: 100) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nwb_sexfemale         -0.05      0.09    -0.22     0.12 1.00     9165     3092\nwb_sexmale            0.23      0.09     0.06     0.40 1.00     8211     2944\nwb_sexother          -0.40      0.12    -0.64    -0.15 1.00     6988     2944\nwb_support            0.82      0.08     0.67     0.96 1.00     5288     3425\nwb_soc_med           -0.12      0.08    -0.27     0.03 1.00     4688     3264\nsupport_sexfemale     0.06      0.11    -0.15     0.27 1.00     7746     2922\nsupport_sexmale      -0.03      0.10    -0.25     0.17 1.00     6896     2807\nsupport_sexother     -0.06      0.15    -0.34     0.23 1.00     8357     3044\nsupport_soc_med       0.60      0.08     0.44     0.76 1.00     9395     2810\n\nFurther Distributional Parameters:\n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma_wb          0.61      0.05     0.53     0.70 1.00     6056     2721\nsigma_support     0.80      0.06     0.70     0.92 1.00     7732     2924\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n## Missing Data\n\nTo deal with missing data, the default behavior of `brms` is **complete case analysis**, which removes all the rows with any missing values. \n\n* Even if we decide to conduct complete case analysis, it is best to remove these cases ourselves.\n\n* We still may prefer to omit cases with missing outcome values. \n\nTwo better options available with `brms`:\n\n1. Multiple imputation\n\n2. Simultaneous sampling\n\n\n## Missing Data\n\nFirst's let's load in, filter out missing outcome values, and scale the variables. \n\n* Use of `na.rm = TRUE` means to standardize relative to the available data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- read_csv(\"emerging_adult.csv\")\nd <- d %>% filter(!is.na(wb)) %>%\n      mutate(soc_med = (soc_med - mean(soc_med, na.rm = TRUE)) / sd(soc_med, na.rm = TRUE),\n         support = (support - mean(support, na.rm = TRUE)) / sd(support, na.rm = TRUE),\n         wb = (wb - mean(wb, na.rm = TRUE)) / sd(wb, na.rm = TRUE))\n```\n:::\n\n\n\n## Missing Data\n\nTo create a separate multiple imputation `stan` model, we need to use `mice` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_imp <- mice(d, #dataset we use\n              m = 5) #number of data sets to impute\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n iter imp variable\n  1   1  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  1   2  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  1   3  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  1   4  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  1   5  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  2   1  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  2   2  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  2   3  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  2   4  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  2   5  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  3   1  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  3   2  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  3   3  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  3   4  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  3   5  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  4   1  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  4   2  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  4   3  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  4   4  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  4   5  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  5   1  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  5   2  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  5   3  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  5   4  age  mind  belong  idea  soc_med  moa_ach  moa_import\n  5   5  age  mind  belong  idea  soc_med  moa_ach  moa_import\n```\n\n\n:::\n:::\n\n\n## Missing Data\n\nFor simplicity, we will fit the multiple regression (not mediation) model.\n\n* Note that we now use `brm_multiple()` intead of `brm()`\n\nIf you run this code on your own machine, you may notice that it runs **5 separate models** for the 5 imputed datasets. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrm_mod <- wb ~ support + soc_med\n\nbrm_prior <- prior(normal(0, .1), class = \"Intercept\") + \n             prior(normal(0, .5), class = \"b\") + \n             prior(exponential(1), class = \"sigma\")\n\nmice_mod <- brm_multiple(brm_mod,\n                         d_imp,\n                         family = gaussian(link = \"identity\"),\n                         prior = brm_prior)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nusing C compiler: ‘Apple clang version 17.0.0 (clang-1700.6.3.2)’\nusing SDK: ‘MacOSX26.2.sdk’\nclang -arch arm64 -std=gnu2x -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/Core:19:\n/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: 'cmath' file not found\n  679 | #include <cmath>\n      |          ^~~~~~~\n1 error generated.\nmake: *** [foo.o] Error 1\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.31 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.044 seconds (Warm-up)\nChain 1:                0.049 seconds (Sampling)\nChain 1:                0.093 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 7e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.045 seconds (Warm-up)\nChain 2:                0.041 seconds (Sampling)\nChain 2:                0.086 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 7e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.044 seconds (Warm-up)\nChain 3:                0.047 seconds (Sampling)\nChain 3:                0.091 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.044 seconds (Warm-up)\nChain 4:                0.046 seconds (Sampling)\nChain 4:                0.09 seconds (Total)\nChain 4: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 9e-06 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.044 seconds (Warm-up)\nChain 1:                0.048 seconds (Sampling)\nChain 1:                0.092 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 7e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.043 seconds (Warm-up)\nChain 2:                0.049 seconds (Sampling)\nChain 2:                0.092 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 7e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.046 seconds (Warm-up)\nChain 3:                0.041 seconds (Sampling)\nChain 3:                0.087 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.045 seconds (Warm-up)\nChain 4:                0.048 seconds (Sampling)\nChain 4:                0.093 seconds (Total)\nChain 4: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.048 seconds (Warm-up)\nChain 1:                0.044 seconds (Sampling)\nChain 1:                0.092 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 8e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.046 seconds (Warm-up)\nChain 2:                0.05 seconds (Sampling)\nChain 2:                0.096 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 9e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.044 seconds (Warm-up)\nChain 3:                0.052 seconds (Sampling)\nChain 3:                0.096 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 8e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.046 seconds (Warm-up)\nChain 4:                0.043 seconds (Sampling)\nChain 4:                0.089 seconds (Total)\nChain 4: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.046 seconds (Warm-up)\nChain 1:                0.051 seconds (Sampling)\nChain 1:                0.097 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 7e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.044 seconds (Warm-up)\nChain 2:                0.047 seconds (Sampling)\nChain 2:                0.091 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 8e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.044 seconds (Warm-up)\nChain 3:                0.041 seconds (Sampling)\nChain 3:                0.085 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.045 seconds (Warm-up)\nChain 4:                0.046 seconds (Sampling)\nChain 4:                0.091 seconds (Total)\nChain 4: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 9e-06 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.09 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.047 seconds (Warm-up)\nChain 1:                0.049 seconds (Sampling)\nChain 1:                0.096 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 8e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.08 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.047 seconds (Warm-up)\nChain 2:                0.047 seconds (Sampling)\nChain 2:                0.094 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 7e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.044 seconds (Warm-up)\nChain 3:                0.041 seconds (Sampling)\nChain 3:                0.085 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 7e-06 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.045 seconds (Warm-up)\nChain 4:                0.048 seconds (Sampling)\nChain 4:                0.093 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n\n## Missing Data\n\n`brm_multiple` automatically pools the multiple imputation results, so the model summary looks familiar.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mice_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity \nFormula: wb ~ support + soc_med \n   Data: d_imp (Number of observations: 3132) \n  Draws: 20 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 20000\n\nRegression Coefficients:\n          Estimate Est.Error l-95% CI u-95% CI\nIntercept    -0.00      0.02    -0.03     0.03\nsupport       0.47      0.02     0.44     0.50\nsoc_med       0.01      0.02    -0.02     0.04\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI\nsigma     0.88      0.01     0.86     0.90\n\nDraws were sampled using sampling(NUTS). Overall Rhat and ESS estimates\nare not informative for brm_multiple models and are hence not displayed.\nPlease see ?brm_multiple for how to assess convergence of such models.\n```\n\n\n:::\n:::\n\n\n## Missing Data\n\nAnother way to conduct multiple imputation is with **simultaneous sampling**. \n\n* Set up the model as a series of regressions (like we did with mediation).\n\n* For any variable that has an `NA` value, use `variable | mi() ~ ...`. \n\n* Use `bf()` for each separate equation.\n\n* Can predict missing values based on the prior only (` ~ 1`) or based on other variables in the data (` ~ soc_med`)\n\n\nThis is easiest to see by example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nss_mod <- bf(wb | mi() ~ mi(support) + mi(soc_med)) +\n          bf(soc_med | mi() ~ 1) +\n          bf(support | mi() ~ mi(soc_med)) +\n          set_rescor(FALSE)\n```\n:::\n\n\n## Missing Data\n\nNow, each missing predictor value is its own parameter that can be assigned a prior. Because we standardized the data, a standard normal prior may be reasonable.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_prior(ss_mod, d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n``` nowrap-code\n                  prior     class      coef group    resp dpar nlpar lb ub tag\n   student_t(3, 0, 2.5) Intercept                  socmed                     \n   student_t(3, 0, 2.5)     sigma                  socmed             0       \n                 (flat)         b                 support                     \n                 (flat)         b misoc_med       support                     \n student_t(3, 0.2, 2.5) Intercept                 support                     \n   student_t(3, 0, 2.5)     sigma                 support             0       \n                 (flat)         b                      wb                     \n                 (flat)         b misoc_med            wb                     \n                 (flat)         b misupport            wb                     \n student_t(3, 0.1, 2.5) Intercept                      wb                     \n   student_t(3, 0, 2.5)     sigma                      wb             0       \n       source\n      default\n      default\n      default\n (vectorized)\n      default\n      default\n      default\n (vectorized)\n (vectorized)\n      default\n      default\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nss_prior <- prior(normal(0, .1), class = \"Intercept\", resp = \"wb\") + \n            prior(normal(0, 1), class = \"Intercept\", resp = \"socmed\") + \n            prior(normal(0, 1), class = \"Intercept\", resp = \"support\") + \n            prior(normal(0, .5), class = \"b\", resp = \"wb\") + \n            prior(normal(0, .5), class = \"b\", resp = \"support\") + \n            prior(exponential(1), class = \"sigma\", resp = \"wb\") + \n            prior(exponential(1), class = \"sigma\", resp = \"socmed\") + \n            prior(exponential(1), class = \"sigma\", resp = \"support\") \n```\n:::\n\n\n\n\n## Missing Data\n\nFit the model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nss_fit <- brm(ss_mod,\n            family = gaussian(link = \"identity\"),\n            d, prior = ss_prior)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRunning /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c\nusing C compiler: ‘Apple clang version 17.0.0 (clang-1700.6.3.2)’\nusing SDK: ‘MacOSX26.2.sdk’\nclang -arch arm64 -std=gnu2x -I\"/Library/Frameworks/R.framework/Resources/include\" -DNDEBUG   -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/Rcpp/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/unsupported\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/BH/include\" -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/src/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppParallel/include/\"  -I\"/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1   -I/opt/R/arm64/include    -fPIC  -falign-functions=64 -Wall -g -O2  -c foo.c -o foo.o\nIn file included from <built-in>:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/Dense:1:\nIn file included from /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/Core:19:\n/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:679:10: fatal error: 'cmath' file not found\n  679 | #include <cmath>\n      |          ^~~~~~~\n1 error generated.\nmake: *** [foo.o] Error 1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0.000525 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 5.25 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 2.65 seconds (Warm-up)\nChain 1:                2.152 seconds (Sampling)\nChain 1:                4.802 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 0.000309 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 3.09 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 2.721 seconds (Warm-up)\nChain 2:                2.449 seconds (Sampling)\nChain 2:                5.17 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 0.000306 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 3.06 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 2.537 seconds (Warm-up)\nChain 3:                2.255 seconds (Sampling)\nChain 3:                4.792 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 0.000293 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 2.93 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 2.515 seconds (Warm-up)\nChain 4:                2.283 seconds (Sampling)\nChain 4:                4.798 seconds (Total)\nChain 4: \n```\n\n\n:::\n:::\n\n\n## Missing Data\n\nView the fitted model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(ss_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n``` nowrap-code\n Family: MV(gaussian, gaussian, gaussian) \n  Links: mu = identity\n         mu = identity\n         mu = identity \nFormula: wb | mi() ~ mi(support) + mi(soc_med) \n         soc_med | mi() ~ 1 \n         support | mi() ~ mi(soc_med) \n   Data: d (Number of observations: 3132) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nwb_Intercept         -0.00      0.02    -0.03     0.03 1.00     7033     2922\nsocmed_Intercept     -0.00      0.02    -0.04     0.03 1.00     7599     2815\nsupport_Intercept    -0.00      0.02    -0.03     0.03 1.00     8866     2988\nwb_misupport          0.47      0.02     0.43     0.50 1.00     7213     2844\nwb_misoc_med          0.01      0.02    -0.02     0.04 1.00     7079     3095\nsupport_misoc_med     0.21      0.02     0.18     0.25 1.00     8491     2963\n\nFurther Distributional Parameters:\n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma_wb          0.88      0.01     0.86     0.91 1.00     8836     2731\nsigma_socmed      1.00      0.01     0.98     1.03 1.00     8043     2960\nsigma_support     0.98      0.01     0.95     1.00 1.00     7573     2939\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n## Activity\n\nSuppose we want to generate data from a partial mediation model where `X` causes `Z` both directly and through a mediator `Y`. This relationship is visualized as follows:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Regression_for_Causal_Inference_II_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n## Activity\n\n1. Based on the model on the previous slide, simulate `X`, `Y` and `Z`:\n    \n    -   150 sample size.\n    -   `X` has an effect on `Y`.\n    -   `X` and `Y` have effect on `Z`.\n    -   Create a data set named \"dat\" containing variables above.\n    -   Standardize all variables.\n\n\n\n2.   Run a multiple regression (not a mediation) model using `brms` with priors $a \\sim N(0, .1)$, $b \\sim N(0, 1)$, $\\sigma \\sim Exp(1)$\n\n3. What is your expectation of the result? Does the result meet your expectation?\n\n4.   How would you modify the model to more correctly match the data-generating mechanism?\n\n## Activity\n\nAdd ten missing data to the `X` variable using the following code:\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1678)\nX[sample(length(X), 10)] <- NA\n\n# be sure to add this new X to your dataset\n```\n:::\n\n\nUse multiple imputation method to run the **correct** model from your perspective.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}