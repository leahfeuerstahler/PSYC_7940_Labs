{
  "hash": "f39ceeb62dfad85322c3f3d597c454c0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 3: Continuous Probability\"\ndate: February 4, 2026\n---\n\n\n\n::: {.cell}\n\n:::\n\n\n## Review\n\n-   Last week we learned how to simulate data from discrete distributions and create visualizations.\n\n-   If variable $X$ follows a discrete distribution, it means the outcome of the variable $X$ is categorical:\n\n$$X \\sim binom(n, p)$$\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(x = c(0:3), size = 3, prob=0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.125 0.375 0.375 0.125\n```\n\n\n:::\n:::\n\n\n-   Today, we will learn about continuous distributions, for which probabilities are found for an interval of $X$ instead of at specific values.\n\n## Overview\n\nMajor differences between continuous distributions and discrete distributions:\n\n  -   Probability vs. density\n    \nSummarizing continuous distributions\n\n  -   Mean, Median, Mode\n  -   Quantiles \n  -   Cumulative distribution\n  -   Intervals\n\n## Features of Continuous Variables\n\nIn discrete distributions, we read probabilities directly from `d` functions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(x = 0:3, size = 3, prob=0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.125 0.375 0.375 0.125\n```\n\n\n:::\n:::\n\n\nHowever, continuous distributions give **densities** instead of **probabilities**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndexp(x = 0:3, rate = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.000000000 0.270670566 0.036631278 0.004957504\n```\n\n\n:::\n:::\n\n\nNote: densities can be >1\n\n\n## Features of Continuous Distributions\n\nProbabilities for continuous distributions are calculated as **areas under the curve** corresponding to **intervals** of the variable\n\n-   For example, 68% of the standard normal distribution is between -1 and 1.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Continuous_Probability_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n## Calculate Probability\n\n- `p` functions give **cumulative probabilities**, the proportion of the distribution that is below a certain point `q`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(q = 1, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8413447\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = data.frame(x = c(-3:3)), aes(x))+\n  stat_function(fun = dnorm, args = list(mean = 0, sd = 1))+\n  geom_area(stat = \"function\", fun = dnorm, \n            xlim = c(-3,1), fill = \"grey\")\n```\n\n::: {.cell-output-display}\n![](Continuous_Probability_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\n## Calculate Probability\n\nWe can arrive at the same result by integrating over the `dnorm` function:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nintegrate(dnorm, lower = -Inf, upper = 1, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.8413448 with absolute error < 1.5e-05\n```\n\n\n:::\n:::\n\n\n\nIntegration can be helpful over a specific range of values:\n    \n\n::: {.cell}\n\n```{.r .cell-code}\nintegrate(dnorm, lower = -1, upper = 1, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n0.6826895 with absolute error < 7.6e-15\n```\n\n\n:::\n:::\n\n\nHow to get the same result with `pnorm`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(1, mean = 0, sd = 1) - pnorm(-1, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6826895\n```\n\n\n:::\n:::\n\n\n## Calculate Probability\n\nQuantiles and cumulative distribution\n\n  -   `q` represents the quantile of a function\n  -   `p` represents the cumulative distribution\n    \nFor example, if we want to investigate the probability **below** 1 of the standard normal distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(1, mean=0, sd=1) #lower.tail = TRUE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8413447\n```\n\n\n:::\n:::\n\n\n\nIf we want to investigate the probability **above** 1 of the standard normal distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(1, mean=0, sd=1, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1586553\n```\n\n\n:::\n:::\n\n\n## Calculate Probability\n\nQuantiles and cumulative distribution\n\n- The quantile function is the inverse function of the cumulative distribution function. \n\n- The quantile is the point of the distribution below which lies  a certain % of the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(p = 0.8, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8416212\n```\n\n\n:::\n:::\n\n\n`qnorm` is the inverse of `pnorm`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(q = 0.8416212, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8\n```\n\n\n:::\n:::\n\n\n## Probability through Simulation\n\n-   Simulate many observations from the distribution.\n-   Find the proportion of data in a certain interval.\n-   Below, we take 10,000 samples. The more data we simulate, the more accurate the result.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(8949)\nsample_10000 <- rnorm(10000, mean = 0, sd = 1)\nmean(sample_10000<1 & sample_10000>-1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6824\n```\n\n\n:::\n:::\n\n\nThe simulated answer is close to the exact answer:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(q = 1, mean = 0, sd = 1) - pnorm(q = -1, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.6826895\n```\n\n\n:::\n:::\n\n\nAlthough it may seem silly to simulate data when an exact answer is available, simulation is useful when the exact probability function is not available.\n\n\n## Summarizing Empirical Distributions\n\nCentral tendency\n\n- Mean, median, mode\n\n- Many distributions have known expressions for these quantities\n\n- See <https://leahmf.com/distributions> or search online\n\n\n**How to summarize central tendency for samples of data, such as simulated data?**\n    \n## Summarizing Empirical Distributions\n\nWe can use simulation to help understand the distribution of empirical samples.\n\n- Mean:\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(sample_10000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.01731999\n```\n\n\n:::\n:::\n\n\n- Median:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmedian(sample_10000)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.01151841\n```\n\n\n:::\n:::\n\n\n## Summarizing Empirical Distributions\n\nHow to find the **mode** from a sample of continuous values?\n\n- For categorical outcomes, the mode is the highest frequency value\n\n- For continuous outcomes, it is very rare to observe the exact same value twice, for example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlength(unique(sample_10000))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10000\n```\n\n\n:::\n:::\n\n\n-   We have 10000 different values, which means that every point is the mode (most frequently occurring point).\n\n-   We can instead find a **highest density interval** to find the most likely **region** of continuous values.\n\n## Summarizing Empirical Distributions\n\nVisualizing the density plot is also a useful method to understand the distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_10000_plot<-data.frame(sample_10000)\nggplot(sample_10000_plot, aes(x = sample_10000))+\n  geom_density()\n```\n\n::: {.cell-output-display}\n![](Continuous_Probability_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n## Summarizing Empirical Distributions\n\nAdditionally, **intervals** are helpful to summarize simulated data.\n\n-   Percentile Intervals\n    - Represents the bounds of the center ___% of values\n    - A 90% percentile interval is bounded by the .05 and .95 quantiles\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(sample_10000, probs = c(0.05, 0.95))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       5%       95% \n-1.674359  1.605895 \n```\n\n\n:::\n:::\n\n\n## Summarizing Empirical Distributions\n\nHighest posterior density (HPD) intervals\n\n-  HPD intervals give the narrowest interval including certain percent of samples.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(coda)\nHPDinterval(as.mcmc(sample_10000), prob=0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         lower    upper\nvar1 -1.912371 2.023588\nattr(,\"Probability\")\n[1] 0.95\n```\n\n\n:::\n:::\n\n\n-   `as.mcmc` can change the dataset to the type of \"Markov Chain Monte Carlo\" object used the `coda` package. We will talk more about it later in this semester.\n\n## Other Distributions in R\n\n-   In lecture, you learned about many continuous distributions. It is easy to simulate data from them in R:\n\n-   `rexp`: exponential\n\n-   `rnorm`: normal\n\n-   `rlnorm`: log-normal\n\n-   `rgamma`: gamma\n\n-   `rbeta`: beta\n\n-   Before using any of them, it is a good habit to visualize each distribution.\n\n## Some Useful Functions in R\n\n- For example the exponential distribution with $\\lambda = 1$:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data.frame(x = c(0, 3), y = c(0, 1)),\n       aes(x = x, y = y))+\n  stat_function(fun = dexp, args = c(rate = 1))\n```\n\n::: {.cell-output-display}\n![](Continuous_Probability_files/figure-revealjs/unnamed-chunk-23-1.png){width=960}\n:::\n:::\n\n\n\n## Activity\n\n1. First, you will work with the gamma distribution.\n\n  - Identify the parameters and allowed parameter ranges of the gamma distribution. Choose specific values to work with.\n  \n  - Use `ggplot` and `stat_function` to draw a gamma distribution curve with your chosen parameters.\n\n  -   Simulate 10,000 samples from the gamma distribution with your chosen parameters. \n  \n  -   Visualize the distribution of your simulated data. \n  \n  -   Calculate the 95% equal-tail interval and HDPI from your simulated data.\n\n  -   Compare your results with a classmate's. If you chose different parameter values, how do the parameters affect your results?\n\n2. Repeat the activity for the beta distribution with parameters of your choice.\n\n",
    "supporting": [
      "Continuous_Probability_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}